# Wharton-Data-Science-Challenge
2024 Wharton Data Science Challenge Submission

When approaching this problem, we decided to use predictive analytics to forecast the group stage and knockout stage winners based on the regular season data. Using Python and its data science libraries, we organized the regular season data into a league table with each team’s wins, losses, draws, points, and win percentages. Sorting the table by team points from greatest to least allowed us to rank the teams based on team records. Then, we used the regular season data to find various team statistics, such as Average xG, Average xG Against, Average Shots, Average Corners, etc. Furthermore, we developed our own statistics called Offense Beat Odds and Defense Beat Odds, which were calculated by subtracting Average Score from Average xG and Average xG Against from Average Score Against, respectively. To account for a potential difference in performance due to home-field advantage, we differentiated between home statistics and away statistics. When selecting a predictive model, our plan was to use a classification model. Logistic Regression and Extreme Gradient Boosting (XGBoost) caught our attention because of their capacity for binary outcome handling along with high predictive accuracy and interpretability. Additionally, these models generate probabilities, making them apt for predicting the knockout matches. When selecting features, we decided to use each teams’ Average Home xG, Average Home xG Against, Average Away xG, Average Away xG Against, Away Defense Beat Odds, Average Home Shots, and Average Away Shots as features in our model. We chose these features based on the results of an ANOVA F-test for feature selection and a correlation matrix with all possible features against the number of wins. In addition, after experimentally testing various combinations of other significant statistics from the previous tests, these seven features resulted in the highest accuracy of 65% for our Logistic Regression model. Therefore, we decided to use the Logistic Regression model with these features to predict the group and knockout stage. Based on this feature selection process, we noticed xG significantly boosted win probability while xG Against significantly diminished win probability, since xG is a more consistent predictor of goals. 
